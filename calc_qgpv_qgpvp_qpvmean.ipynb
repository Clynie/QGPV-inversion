{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALC FULL COLUMN QGPV, QGPVMEAN, QGPVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook calculates QGPV, QGPV perturbation (QGPVP), and QGPV mean as in Melissa's code\n",
    "#Last updated 05/20/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import cartopy.crs as crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from wrf import (getvar, interplevel, to_np, latlon_coords, get_cartopy,\n",
    "                 cartopy_xlim, cartopy_ylim, extract_times, ALL_TIMES, interpz3d, vinterp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define type of tile and desired pressure level\n",
    "#fullphys_expdom or nolatentheat_expdom\n",
    "filetype = \"fullphys_expdom\"                                   #CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file\n",
    "ncfile = Dataset(\"wrfout_\"+filetype+\".nc\", \"r\")\n",
    "\n",
    "# Extract the pressure, geopotential height, and wind variables\n",
    "pressure = getvar(ncfile, \"pressure\",timeidx=ALL_TIMES)\n",
    "z = getvar(ncfile, \"z\", timeidx=ALL_TIMES, units=\"m\")\n",
    "thta = getvar(ncfile, \"th\",timeidx=ALL_TIMES)\n",
    "tmpk = getvar(ncfile, \"tk\",timeidx=ALL_TIMES)\n",
    "ua = getvar(ncfile, \"ua\", timeidx=ALL_TIMES, units=\"kt\")\n",
    "va = getvar(ncfile, \"va\", timeidx=ALL_TIMES, units=\"kt\")\n",
    "height_agl = getvar(ncfile, \"height_agl\", timeidx = ALL_TIMES,units=\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants\n",
    "R = 287.05 #J kg^-1 K^-1\n",
    "kappa=0.2856219 #Rd / cp\n",
    "cp = 1004.7 #J kg^-1 K^-1\n",
    "pref = 1000. #hPa\n",
    "g = 9.80665 #gravity\n",
    "omega = 7.292e-5 #Earth's rotation rate (s^-1)\n",
    "a = 2.e7 / np.pi #Radius of the earth (m)\n",
    "p0=1.e5\n",
    "alpha=-1./5.255877\n",
    "gamma = 0.0065 #lapse rate, (K/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pressure level array\n",
    "pb = 1000. #base pressure\n",
    "pb_half = 975.\n",
    "pt = 100. #top pressure\n",
    "pt_half = 125.\n",
    "p = np.linspace(pb,pt,19) #make array of size 19 with even spacing from base pressure to top pressure\n",
    "#p_half = np.linspace(pb_half,pt_half,18)\n",
    "delp = (p[0] - p[1]) * 100. #Convert to hPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually define phalf based on length of k and pressure values\n",
    "phalf = np.zeros((len(p)-1))\n",
    "for i in range(len(p)-1):\n",
    "    phalf[i] = (p[i+1] + p[i]) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounds for inversion\n",
    "lat1 = 30. #Southern boundary\n",
    "lat2 = 70. #Northern boundary\n",
    "lon1 = 150. #Western boundary\n",
    "lon2 = 250. #Eastern boundary\n",
    "dlat = lat2 - lat1\n",
    "dlon = lon2 - lon1\n",
    "dellatstar = (np.pi/180.) * a\n",
    "dellonstar = (np.pi/180.) * a\n",
    "sigma1 = dellonstar / dellatstar\n",
    "sigma2 = dellonstar / delp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get times from dataset\n",
    "times = extract_times(ncfile, None)\n",
    "count = np.count_nonzero(times)\n",
    "#Set t, k, i, j indice lengths\n",
    "tlen = len(times)\n",
    "klen = len(p)\n",
    "ilen = np.shape(z[:,:,:,:])[2] #This is really the j index (north-south index)\n",
    "jlen = np.shape(z[:,:,:,:])[3] #This is really the i index (east-west index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format times to be in standard format\n",
    "dattimes = []\n",
    "import pandas as pd\n",
    "for i in range (0, count):\n",
    "    dattimes.append(str(pd.Timestamp(times[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate US Standard Atmosphere/Reference Atmosphere Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard atmosphere geopotential, potential temperature, and stability function\n",
    "def standard_atmosphere(p, p_half):\n",
    "    g=9.8066\n",
    "    kappa=0.2856219\n",
    "    alpha=-1./5.255877\n",
    "    beta=-6341.624\n",
    "    gamma=.0065\n",
    "    R=287.04\n",
    "    cp = 1004.7\n",
    "    p00=1000.\n",
    "    nlevels = p.size\n",
    "    nlevels_half = p_half.size\n",
    "\n",
    "    Z = np.zeros(nlevels)\n",
    "    phi = np.zeros(nlevels)\n",
    "    T = np.zeros(nlevels)\n",
    "    theta = np.zeros(nlevels)\n",
    "\n",
    "    T_half = np.zeros(nlevels)\n",
    "    theta_half = np.zeros(nlevels_half)\n",
    "    dthetadp = np.zeros(nlevels_half)\n",
    "    S = np.zeros(nlevels_half)\n",
    "\n",
    "    for k in np.arange(nlevels):\n",
    "        if (p[k] > 226.32):\n",
    "            Z[k] = (288.15/gamma) * ( 1. - (1013.25/p[k])**alpha)\n",
    "            T[k] = 288.15 - 0.0065*Z[k]\n",
    "            theta[k] = T[k] * (1000./p[k])**(R/cp)\n",
    "        else:\n",
    "            T[k] = 216.65\n",
    "            Z[k] = (11.e3+beta*np.log(p[k]/226.32))\n",
    "            theta[k] = T[k] * (p00/p[k])**(R/cp)\n",
    "                \n",
    "    for k in np.arange(nlevels_half):\n",
    "        if (p_half[k] > 226.32):\n",
    "            T_half[k] = 288.15 - gamma*Z[k]\n",
    "            theta_half[k] = T_half[k] * (p00/p_half[k])**(R/cp)\n",
    "        else:\n",
    "            T_half[k] = 216.65\n",
    "            theta_half[k] = T_half[k] * (p00/p_half[k])**(R/cp)\n",
    "    \n",
    "    for k in np.arange(nlevels_half):\n",
    "        dthetadp[k] = (theta[k+1] - theta[k])/(1.e2*(p[k+1]-p[k]))\n",
    "        S[k] =  -R*(T_half[k]/theta_half[k])*dthetadp[k]/(p_half[k]*100.)\n",
    "    return g*Z, T, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standard atmosphere geopotential (geop), potential temp (tmpk), and stability\n",
    "SAgeop, SAtmpk, stability = standard_atmosphere(p, phalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hght = np.zeros((tlen, klen, ilen, jlen))\n",
    "levels = [1000,950,900,850,800,750,700,650,600,550,500,450,400,350,300,250,200,150,100]\n",
    "for t in range(tlen):\n",
    "    hght[t,:,:,:] = vinterp(ncfile,z[t,:,:,:],'p',levels,extrapolate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get lats and lons from wrf file\n",
    "lat = getvar(ncfile, \"lat\")\n",
    "lon = getvar(ncfile, \"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate lat and lon min and max for manually defining array lengths\n",
    "latmax = float(np.max(lat))\n",
    "latmin = float(np.min(lat))\n",
    "lonmax = float(np.max(lon))\n",
    "lonmin = float(np.min(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefine lat and lon arrays to be smaller size, 1 degree spacing\n",
    "lat = np.arange(latmin,latmax,((latmax-latmin)/jlen))\n",
    "lon = np.arange(lonmin,lonmax,((lonmax-lonmin)/ilen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Coriolis parameter\n",
    "lenlat = len(lat)\n",
    "cor = np.zeros((lenlat))\n",
    "for j in range(lenlat):\n",
    "    cor[j] = 2. * omega * np.sin(lat[j]*(np.pi / 180.)) # degrees to radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Rossby parameter (beta), variation in Coriolis force with respect to changing latitude\n",
    "beta = np.zeros((lenlat))\n",
    "for j in range(lenlat):\n",
    "    beta[j] = (2. * omega / a) * np.cos(lat[j] * (np.pi / 180.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean Coriolis Parameter weighted by latitude\n",
    "fo = 0.\n",
    "for j in range(lenlat):\n",
    "    fo = fo + (cor[j] / (dlat+1)) #fo = fo + (cor[j] / (jlen-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate QGPV coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosPoint = np.zeros((lenlat))\n",
    "cosPlus = np.zeros((lenlat)) \n",
    "cosPlushalf = np.zeros((lenlat)) \n",
    "cosMinus = np.zeros((lenlat)) \n",
    "cosMinushalf = np.zeros((lenlat))\n",
    "\n",
    "for i in range(lenlat):\n",
    "    cosPoint[i] = np.cos(lat[i] * (np.pi / 180.))\n",
    "    cosPlus[i] = np.cos((lat[i] + 1.0) * np.pi / 180.)\n",
    "    cosPlushalf[i] = np.cos((lat[i] + 0.5) * np.pi / 180.)\n",
    "    cosMinus[i] = np.cos((lat[i] - 1.0) * np.pi / 180.)\n",
    "    cosMinushalf[i] = np.cos((lat[i] - 0.5) * np.pi / 180.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients on relative vorticity\n",
    "A1_rel = np.zeros((lenlat))\n",
    "A2_rel = np.zeros((lenlat))\n",
    "A3_rel = np.zeros((lenlat))\n",
    "A4_rel = np.zeros((lenlat))\n",
    "A5_rel = np.zeros((lenlat))\n",
    "\n",
    "for j in range(lenlat):\n",
    "    A1_rel[j] = 1. / ((cosPoint[j] * dellonstar) ** 2.) # goes on phi(k,i-1,j)\n",
    "    A2_rel[j] = cosMinushalf[j]/(cosPoint[j]*dellatstar ** 2.) # goes on phi(k,i,j-1)\n",
    "    A3_rel[j] = (-2. / (cosPoint[j] * dellonstar) ** 2.) - (cosPlushalf[j] / (cosPoint[j] * dellatstar ** 2.)) - (cosMinushalf[j] / (cosPoint[j] * dellatstar ** 2.)) #goes on phi(k,i,j)\n",
    "    A4_rel[j] = 1. / ((cosPoint[j] * dellonstar) ** 2.) # goes on phi(k,i+1,j) \n",
    "    A5_rel[j] = cosPlushalf[j] / (cosPoint[j] * dellatstar ** 2.) # goes on phi(k,i,j+1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients for QGPV\n",
    "A1_qgpv = np.zeros((lenlat)) # goes on phi(t,j,i-1,k)\n",
    "A2_qgpv = np.zeros((lenlat))\n",
    "A2i_qgpv = np.zeros((lenlat)) # goes on phi(t,j-1,i,k)\n",
    "A3_qgpv = np.zeros((lenlat, len(p))) # goes on phi(t,j,i,k) has parts in vert, meridional\n",
    "A3i_qgpv = np.zeros((lenlat, len(p))) # goes on phi(t,j,i,k) has parts in vert, meridional\n",
    "A4_qgpv = np.zeros((lenlat)) # goes on phi(t,j+1,i,k)\n",
    "A4i_qgpv = np.zeros((lenlat)) # goes on phi(t,j+1,i,k)\n",
    "A5_qgpv= np.zeros((lenlat)) # goes on phi(t,j,i+1,k) \n",
    "A6_qgpv = np.zeros((len(p))) # goes on phi(t,j,i,k-1) \n",
    "A7_qgpv = np.zeros((len(p))) # goes on phi(t,j,i,k+1) \n",
    "A8_qgpv = dellonstar ** 2. # goes on q-f \n",
    "\n",
    "\n",
    "for j in range(lenlat):\n",
    "    A1_qgpv[j] = 1. / (fo * cosPoint[j] ** 2.) \n",
    "    A2_qgpv[j] = (sigma1 ** 2.) * cosMinus[j] / (fo * cosPoint[j])\n",
    "    A2i_qgpv[j] = (sigma1 ** 2.) * cosMinushalf[j] / (fo * cosPoint[j]) \n",
    "    A4_qgpv[j] = ((sigma1 ** 2.) * cosPlus[j] / (fo * cosPoint[j]))\n",
    "    A4i_qgpv[j] = ((sigma1 ** 2.) * cosPlushalf[j] / (fo * cosPoint[j])) \n",
    "    A5_qgpv[j] = 1. / (fo * cosPoint[j] ** 2.)\n",
    "    \n",
    "    for k in range(2,len(p)-1):\n",
    "        A3_qgpv[j,k] = -1. * ((2. / (fo * cosPoint[j] ** 2.)) + ((sigma1 ** 2.) / fo) * ((cosPlus[j] / cosPoint[j]) + (cosMinus[j] / cosPoint[j])) + ((4. * fo * sigma2 ** 2.) * ((1. / stability[k-1]) + (1. / stability[k])))) \n",
    "        A3i_qgpv[j,k] = (-2. / (fo * cosPoint[j] ** 2.)) + (((sigma1 ** 2.) / fo) * ((-cosPlushalf[j] / cosPoint[j]) - (cosMinushalf[j] / cosPoint[j]))) + ((fo * sigma2 ** 2.) * ((-1. / stability[k-1]) - (1. / stability[k]))) \n",
    "        A6_qgpv[k] = (fo * sigma2 ** 2.) / stability[k-1] \n",
    "        A7_qgpv[k] = (fo * sigma2 ** 2.) / stability[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define arrays to store calculations\n",
    "qgpv_tmp = np.zeros((tlen, klen, ilen, jlen))\n",
    "qgpv = np.zeros((tlen, klen, ilen, jlen))\n",
    "qgpvp = np.zeros((tlen, klen, ilen, jlen))\n",
    "geop = np.zeros((tlen, klen, ilen, jlen))\n",
    "geopper = np.zeros((tlen, klen, ilen, jlen))\n",
    "rel_vor = np.zeros((tlen, klen, ilen, jlen))\n",
    "strvor = np.zeros((tlen, klen, ilen, jlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape SAgeop for calculation\n",
    "SAgeop1 = np.zeros((tlen, klen, ilen, jlen))\n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        SAgeop1[t,k,:,:] = SAgeop[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract standard atmosphere geopotential\n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        geop[t,k,:,:] = (g * hght[t,k,:,:]) - SAgeop1[t,k,:,:]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape SAtmpk for calculation\n",
    "SAtmpk1 = np.zeros((tlen, klen, ilen, jlen))\n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        SAtmpk1[t,k,:,:] = SAtmpk[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define arrays for storing calculations\n",
    "qgpvmean = np.zeros((klen, ilen, jlen)) #mean QGPV whole time period\n",
    "geopmean = np.zeros((klen, ilen, jlen)) #mean geopotential\n",
    "tmpkmean = np.zeros((klen, ilen, jlen)) #mean temp in Kelvin\n",
    "tmpkmean_SArem = np.zeros((klen, ilen, jlen))\n",
    "tmpk_SArem = np.zeros((tlen, klen, ilen, jlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract standard atmosphere temperature (from QGPV derivation, QG thermo equation)\n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        tmpk_SArem[t,k,:,:] = tmpk[t,k,:,:] - SAtmpk1[t,k,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate geopotential, temp (K) anomalies\n",
    "#MEAN TMPK ANOMALIES TAKE AWHILE TO RUN\n",
    "for k in range(klen):\n",
    "    for i in range(ilen):\n",
    "        for j in range(jlen):\n",
    "            geopmean[k,i,j]= np.squeeze(np.mean(geop[0:,k,i,j])) \n",
    "            #tmpkmean[k,i,j]=np.squeeze(np.mean(tmpk[0:-1,k,i,j])) \n",
    "            #tmpkmean_SArem[k,i,j]=np.squeeze(np.mean(tmpk_SArem[0:-1,k,i,j])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate relative vorticity\n",
    "for t in range(tlen):\n",
    "    for k in range(1, klen-1):\n",
    "        for i in range(1, ilen-1):\n",
    "            for j in range(1, jlen-1): \n",
    "                rel_vor[t,k,i,j] = ((A1_rel[j] * geop[t,k,i-1,j]) + (A2_rel[j] * geop[t,k,i,j-1]) + (A3_rel[j] * geop[t,k,i,j]) + (A4_rel[j] * geop[t,k,i+1,j]) + (A5_rel[j] * geop[t,k,i,j+1])) / fo\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stretching vorticity  \n",
    "str_vortot = np.zeros((tlen, klen, ilen, jlen))  \n",
    "first_der = np.zeros((tlen, klen, ilen, jlen))\n",
    "\n",
    "for t in range(tlen):\n",
    "    for k in range(klen-1):\n",
    "        first_der[t,k,:,:] = (1. / stability[k]) * ((geop[t,k,:,:] - geop[t,k+1,:,:]) / (delp))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More stretching vorticity calculations\n",
    "for t in range(tlen):\n",
    "    for k in range(1,klen-1):\n",
    "        str_vortot[t,k,:,:]= fo * (first_der[t,k-1,:,:] - first_der[t,k,:,:]) / (delp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate qgpv for interior points \n",
    "for t in range(tlen):\n",
    "    for k in range(1, klen-1):\n",
    "        for i in range(1, ilen-1):\n",
    "            for j in range(1, jlen-1):\n",
    "                qgpv_tmp[t,k,i,j]=str_vortot[t,k,i,j]+rel_vor[t,k,i,j]+cor[j] #Using full Coriolis force, not beta plane or f plane approximations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hydrostatic relationship, set upper and lower\n",
    "# boundaries using temperature \n",
    "for t in range(tlen):\n",
    "    for i in range(ilen):\n",
    "        for j in range(jlen):          \n",
    "            qgpv_tmp[t,0,i,j] = ((-1.0*phalf[0]*100.)/R)*((geop[t,0,i,j]-geop[t,1,i,j])/(delp)) \n",
    "            qgpv_tmp[t,klen-1,i,j] = ((-1.0*phalf[klen-2]*100.)/R)*((geop[t,klen-3,i,j]-geop[t,klen-2,i,j])/delp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign qgpv values to array qgpv\n",
    "qgpv = qgpv_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sides equal to values just inside boundary as done for geopper \n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        for i in range(ilen):\n",
    "            qgpv[t,k,i,0] = qgpv[t,k,i,1]\n",
    "            qgpv[t,k,i,jlen-1] = qgpv[t,k,i,jlen-2]\n",
    "        for j in range(jlen): \n",
    "            qgpv[t,k,0,j] = qgpv[t,k,1,j]\n",
    "            qgpv[t,k,ilen-1,j] = qgpv[t,k,ilen-2,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sides equal to values just inside boundary as done for geopper \n",
    "for t in range(tlen):\n",
    "    for k in range(klen):\n",
    "        for i in range(ilen):\n",
    "            qgpv[t,k,i,0] = 0\n",
    "            qgpv[t,k,i,jlen-1] = 0\n",
    "        for j in range(jlen): \n",
    "            qgpv[t,k,0,j] = 0\n",
    "            qgpv[t,k,ilen-1,j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean qgpv INCLUDING THETA TOP AND BOTTOM\n",
    "#For whole time period\n",
    "#qgpv[0:-1,k,i,j]\n",
    "\n",
    "#For full_phys:\n",
    "#Most rapid development (3 hour pressure tendencies >= -6mb/hr)\n",
    "#12 UTC 11/26 to 00 UTC 11/27\n",
    "#qgpv[8:12,k,i,j]\n",
    "\n",
    "#For no_latent_heat:\n",
    "#Most rapid development (3 hour pressure tendencies >= -6mb/hr)\n",
    "#12 UTC 11/26 to 00 UTC 11/27\n",
    "#qgpv[8:12,k,i,j]\n",
    "\n",
    "qgpvmean_spec = np.zeros((klen, ilen, jlen)) #mean QGPV specified time period\n",
    "\n",
    "for k in range(klen):\n",
    "    for i in range(ilen):\n",
    "        for j in range(jlen):\n",
    "            qgpvmean[k,i,j] = np.squeeze(np.mean(qgpv[0:,k,i,j])) #Taking mean over whole time period\n",
    "            qgpvmean_spec[k,i,j] = np.squeeze(np.mean(qgpv[8:12,k,i,j])) #Taking mean over specified time period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over u and v wind to get mean wind for QGPV MEAN whole time period plot\n",
    "#This cell takes about 15 min to run but produces good results!\n",
    "\n",
    "#uamean = np.zeros((klen, ilen, jlen))\n",
    "#vamean = np.zeros((klen, ilen, jlen))\n",
    "#for k in range(klen):\n",
    "    #for i in range(ilen):\n",
    "        #for j in range(jlen):\n",
    "            #uamean[k,i,j] = np.squeeze(np.mean(ua[0:,k,i,j])) #Taking mean of u wind\n",
    "            #vamean[k,i,j] = np.squeeze(np.mean(va[0:,k,i,j])) #Taking mean of v wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over u and v wind to get mean wind for QGPV MEAN specified plot\n",
    "#This cell takes about 15 min to run but produces good results!\n",
    "\n",
    "#uamean_spec = np.zeros((klen, ilen, jlen))\n",
    "#vamean_spec = np.zeros((klen, ilen, jlen))\n",
    "#for k in range(klen):\n",
    "    #for i in range(ilen):\n",
    "        #for j in range(jlen):\n",
    "            #uamean_spec[k,i,j] = np.squeeze(np.mean(ua[8:12,k,i,j])) #Taking mean of u wind\n",
    "            #vamean_spec[k,i,j] = np.squeeze(np.mean(va[8:12,k,i,j])) #Taking mean of v wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate QGPV anomalies, qgpvp, and geopotential anomalies\n",
    "geopp = np.zeros((tlen,klen, ilen, jlen))\n",
    "for t in range(tlen):\n",
    "    qgpvp[t,:,:,:] = qgpv[t,:,:,:] - qgpvmean[:,:,:]\n",
    "    geopp[t,:,:,:] = geop[t,:,:,:] - geopmean[:,:,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START HERE TO RUN PLOTTING SEQUENCE\n",
    "\n",
    "#Desired pressure (levtitle) and corresponding k value\n",
    "levtitle = '300'                                                   #CHANGE                                                              #CHANGE\n",
    "if levtitle == '850':\n",
    "    lev = 3\n",
    "if levtitle == '300':\n",
    "    lev = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "# Getting back the objects:\n",
    "#with open('qgpv_vars_'+levtitle+'_'+filetype+'.pkl', 'rb') as f:\n",
    "    #qgpv, qgpvp, qgpvmean, geop, geopp, geopmean, uamean, vamean, uamean_spec, vamean_spec, SAgeop, SAtmpk, stability = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING FOR QGPVMEAN whole time period\n",
    "# Get the map projection information\n",
    "cart_proj = get_cartopy(wrfin=ncfile)\n",
    "    \n",
    "lats, lons = latlon_coords(z)\n",
    "dx, dy = mpcalc.lat_lon_grid_deltas(lons, lats)\n",
    "    \n",
    "# Create the figure\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = plt.axes(projection=cart_proj)\n",
    "# Download and add the states and coastlines\n",
    "states = NaturalEarthFeature(category=\"cultural\", scale=\"50m\",\n",
    "                             facecolor=\"none\",\n",
    "                             name=\"admin_1_states_provinces_shp\")\n",
    "ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n",
    "ax.coastlines('50m', linewidth=0.8)\n",
    "\n",
    "leveof_qgpv = np.arange(-100, 100, 1)\n",
    "tmp1 = 10. ** 4. * np.squeeze(qgpvmean[lev,:,:])\n",
    "tmp1[tmp1 > 50.] = np.nan\n",
    "tmp1[tmp1 < -50.] = np.nan\n",
    "\n",
    "tmp2 = np.squeeze(uamean[lev,:,:])\n",
    "tmp3 = np.squeeze(vamean[lev,:,:])\n",
    "\n",
    "qgcs = plt.pcolormesh(to_np(lons), to_np(lats), to_np(tmp1),\n",
    "                                cmap='bwr', vmin=-10., vmax=15.,\n",
    "                                transform=crs.PlateCarree())\n",
    "plt.colorbar(qgcs, ax=ax, orientation=\"horizontal\", pad=.05)\n",
    "\n",
    "# Add the wind barbs, only plotting every 15th data point.             #UNCOMMENT\n",
    "plt.barbs(to_np(lons[::15,::15]), to_np(lats[::15,::15]),\n",
    "        to_np(tmp2[::15, ::15]), to_np(tmp3[::15, ::15]),\n",
    "        transform=crs.PlateCarree(), length=5)\n",
    "\n",
    "# Set the map bounds\n",
    "ax.set_xlim(cartopy_xlim(z))\n",
    "ax.set_ylim(cartopy_ylim(z))\n",
    "\n",
    "ax.gridlines()\n",
    "\n",
    "ax.set_title('WRF '+levtitle+'-hPa Mean QGPV (Scaled $10^4$) ($s^{-1}$) and Wind Barbs (kt) \\n Valid From '+dattimes[0]+' UTC to '+dattimes[-1]+' UTC')\n",
    "    \n",
    "plt.savefig('plots/qgpvmean/QGPVMEAN_'+levtitle+'_'+filetype+'_'+dattimes[0]+'- '+dattimes[-1]+'.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING FOR QGPVMEAN specified time period\n",
    "# Get the map projection information\n",
    "cart_proj = get_cartopy(wrfin=ncfile)\n",
    "    \n",
    "lats, lons = latlon_coords(z)\n",
    "dx, dy = mpcalc.lat_lon_grid_deltas(lons, lats)\n",
    "    \n",
    "# Create the figure\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = plt.axes(projection=cart_proj)\n",
    "# Download and add the states and coastlines\n",
    "states = NaturalEarthFeature(category=\"cultural\", scale=\"50m\",\n",
    "                             facecolor=\"none\",\n",
    "                             name=\"admin_1_states_provinces_shp\")\n",
    "ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n",
    "ax.coastlines('50m', linewidth=0.8)\n",
    "\n",
    "leveof_qgpv = np.arange(-100, 100, 1)\n",
    "tmp1 = 10. ** 4. * np.squeeze(qgpvmean_spec[lev,:,:])\n",
    "tmp1[tmp1 > 50.] = np.nan\n",
    "tmp1[tmp1 < -50.] = np.nan\n",
    "\n",
    "tmp2 = np.squeeze(uamean_spec[lev,:,:])\n",
    "tmp3 = np.squeeze(vamean_spec[lev,:,:])\n",
    "\n",
    "qgcs = plt.pcolormesh(to_np(lons), to_np(lats), to_np(tmp1),\n",
    "                                cmap='bwr', vmin=-10., vmax=15.,\n",
    "                                transform=crs.PlateCarree())\n",
    "plt.colorbar(qgcs, ax=ax, orientation=\"horizontal\", pad=.05)\n",
    "\n",
    "# Add the wind barbs, only plotting every 15th data point.             #UNCOMMENT\n",
    "plt.barbs(to_np(lons[::15,::15]), to_np(lats[::15,::15]),\n",
    "        to_np(tmp2[::15, ::15]), to_np(tmp3[::15, ::15]),\n",
    "        transform=crs.PlateCarree(), length=5)\n",
    "\n",
    "# Set the map bounds\n",
    "ax.set_xlim(cartopy_xlim(z))\n",
    "ax.set_ylim(cartopy_ylim(z))\n",
    "\n",
    "ax.gridlines()\n",
    "\n",
    "ax.set_title('WRF '+levtitle+'-hPa Mean QGPV (Scaled $10^4$) ($s^{-1}$) and Wind Barbs (kt) \\n Valid From '+dattimes[8]+' UTC to '+dattimes[12]+' UTC')\n",
    "    \n",
    "plt.savefig('plots/qgpvmean/QGPVMEAN_'+levtitle+'_'+filetype+'_'+dattimes[8]+'- '+dattimes[12]+'.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on time:  2019-11-25 12:00:00\n",
      "Working on time:  2019-11-25 15:00:00\n",
      "Working on time:  2019-11-25 18:00:00\n",
      "Working on time:  2019-11-25 21:00:00\n",
      "Working on time:  2019-11-26 00:00:00\n",
      "Working on time:  2019-11-26 03:00:00\n",
      "Working on time:  2019-11-26 06:00:00\n",
      "Working on time:  2019-11-26 09:00:00\n",
      "Working on time:  2019-11-26 12:00:00\n",
      "Working on time:  2019-11-26 15:00:00\n",
      "Working on time:  2019-11-26 18:00:00\n",
      "Working on time:  2019-11-26 21:00:00\n",
      "Working on time:  2019-11-27 00:00:00\n",
      "Working on time:  2019-11-27 03:00:00\n",
      "Working on time:  2019-11-27 06:00:00\n",
      "Working on time:  2019-11-27 09:00:00\n",
      "Working on time:  2019-11-27 12:00:00\n",
      "Working on time:  2019-11-27 15:00:00\n",
      "Working on time:  2019-11-27 18:00:00\n",
      "Working on time:  2019-11-27 21:00:00\n",
      "Working on time:  2019-11-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#PLOTTING FOR QGPVP (QGPV perturbation)\n",
    "for i in range (0,count):\n",
    "    print(\"Working on time: \", dattimes[i])\n",
    "    \n",
    "    # Get the map projection information\n",
    "    cart_proj = get_cartopy(wrfin=ncfile)\n",
    "    \n",
    "    lats, lons = latlon_coords(z)\n",
    "    dx, dy = mpcalc.lat_lon_grid_deltas(lons, lats)\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    ax = plt.axes(projection=cart_proj)\n",
    "    # Download and add the states and coastlines\n",
    "    states = NaturalEarthFeature(category=\"cultural\", scale=\"50m\",\n",
    "                             facecolor=\"none\",\n",
    "                             name=\"admin_1_states_provinces_shp\")\n",
    "    ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n",
    "    ax.coastlines('50m', linewidth=0.8)\n",
    "    \n",
    "    #Plot qgpvmean\n",
    "    leveof_qgpv = np.arange(-10,11, 1)\n",
    "    tmp1 = 10. ** 4. * np.squeeze(qgpvp[i,lev,:,:])\n",
    "    tmp1[tmp1 > 50.] = np.nan\n",
    "    tmp1[tmp1 < -50.] = np.nan\n",
    "   \n",
    "    qgcs = plt.pcolormesh(to_np(lons), to_np(lats), to_np(tmp1),\n",
    "                                   cmap='bwr', vmin=-10, vmax=10,\n",
    "                                   transform=crs.PlateCarree())\n",
    "    plt.colorbar(qgcs, ax=ax, orientation=\"horizontal\", pad=.05)\n",
    "    \n",
    "    # Add the wind barbs, only plotting every 15th data point.\n",
    "    plt.barbs(to_np(lons[::15,::15]), to_np(lats[::15,::15]),\n",
    "          to_np(ua[i,lev, ::15, ::15]), to_np(va[i,lev, ::15, ::15]),\n",
    "          transform=crs.PlateCarree(), length=5)\n",
    "    \n",
    "    # Set the map bounds\n",
    "    ax.set_xlim(cartopy_xlim(z))\n",
    "    ax.set_ylim(cartopy_ylim(z))\n",
    "\n",
    "    ax.gridlines()\n",
    "\n",
    "    ax.set_title('WRF '+levtitle+'-hPa QGPV Perturbation (Scaled $10^4$) (1/s) and Wind Barbs (kt) \\n Valid Time: {} UTC'.format(dattimes[i]))\n",
    "    \n",
    "    plt.savefig('plots/qgpvp/QGPVP_'+levtitle+'_'+filetype+'_{}.pdf'.format(dattimes[i]))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save important values into pickle file\n",
    "import pickle\n",
    "with open('qgpv_vars_'+levtitle+'_'+filetype+'.pkl', 'wb') as f:\n",
    "    pickle.dump([qgpv, qgpvp, qgpvmean, geop, geopp, geopmean, uamean, vamean, uamean_spec, vamean_spec, SAgeop, SAtmpk, stability], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
